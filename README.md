![IMG-20231115-WA0020 (1)](https://github.com/user-attachments/assets/f63ee171-6b3a-4a58-aa2a-db04bd294e86)



# üëã Hi there!

I am a **Data Analyst** with a strong foundation in mathematics and passion for transforming data into actionable insights.

## üíª Technical Skills
- Programming & Query Languages: SQL, Excel
- Data Visualization & BI Tools: Power BI, Tableau, Excel
- Database Management: Microsoft SQL Server, MySQL, PostgreSQL,J
- Cloud & Collaboration Tools: Microsoft Windows Server, Google Suite, Microsoft Office Suite, Slack, Zoom, Team Viewer
- Project & Delivery Tools: JIRA, Agile (Scrum / Kanban) 

## üéì Education
- MSc in Big Data Analytics ‚Äì *University of Derby* , October 2024 
- BSc in Mathematics ‚Äì *Usmanu Danfodiyo University*, November 2019  


## üíº Experience

### üè¢ Data Analyst  
**Amdari-London, United Kingdom**

*Jan 2025 - Present*

- Spearheaded the development of a KPI dashboard using Power BI
that enhanced decision making, reducing data reporting turnaround
time by 45% and enabling leadership to make faster, more informed
business decisions.
- Conducted sales and customer analytics using Tableau, which led to
identifying high value customer segments, increasing conversion
rates by 30% through targeted marketing strategies.
- Automated weekly and monthly reporting workflows using SQL, and
Power BI, cutting down manual reporting efforts by 50% and ensuring
real-time data accessibility.
- Led a data quality initiative that cleaned and standardized over 1
million records, improving data accuracy by 95% and enhancing the
reliability of business reports.
- Developed predictive models to analyze customer churn trends,
resulting in a 25% reduction in customer attrition by implementing
proactive engagement strategies.
- Partnered with cross-functional teams including marketing and
finance teams to translate business needs into data-driven
solutions, supporting strategic initiatives with clear, actionable
insights.

### üè• Data Analyst  
**UDUTH ‚Äì Usmanu Danfodiyo University Teaching Hospital**  
*Sep 2022 ‚Äì Aug 2023*  
- Worked closely with senior analysts and stakeholders to identify data quality issues, reporting inefficiencies, and process bottlenecks 
within financial and operational datasets, supporting improved forecasting and evidence-based decision-making. 
- Supported the availability, integrity, and reliability of data systems used for operational and financial reporting, ensuring consistent access 
to accurate datasets for analysis and performance monitoring.
- Assisted in data governance and assurance activities, including routine data backups and disaster recovery processes, helping to safeguard 
critical datasets and support business continuity and regulatory compliance. 
- Contributed to the standardisation and optimisation of reporting workflows, improving data accuracy, consistency, and timeliness to 
support management reporting and service planning. 

### üè¢ Data Analyst
**National Automotive Design and Development Council**  
*Dec 2020 ‚Äì Aug 2022*  
- Aggregated and analyzed automotive industry data to uncover market trends, consumer preferences, and pricing opportunities, 
supporting competitive pricing strategies that enhanced market positioning and revenue growth.
- Developed predictive models to forecast revenue trends and customer demand, enabling leadership to make informed decisions on 
pricing, expansion, and supply chain management, fueling sustainable organizational growth. 
- Conducted market and industry analysis by collecting, cleaning, and analysing automotive data related to consumer behaviour, market 
trends, and global industry standards 
- Analysed large and complex datasets to generate insights on automotive performance, manufacturing efficiency, and key financial 
indicators, supporting strategic and operational planning 



## üìä What I Do
I enjoy working on data-driven projects that uncover trends, improve decision-making, and solve real-world problems.
## Projects

## SQL PROJECTS

### [Project 1:AURELIA-STYLES](https://github.com/akhimiejr/Aurelia-Styles)

Aurelia Styles is a multi-store fashion retail brand specializing in premium Afro-
contemporary apparel, footwear, and accessories. With stores across multiple regions
in Nigeria, the company serves a diverse customer base segmented by age, gender, and
loyalty status (VIP vs Regular). Aurelia Styles prides itself on blending traditional
Nigerian designs with modern fashion trends, offering products that cater to both
everyday wear and special occasions.
The company operates a mix of physical stores and sales channels, including in-store,
online, and mobile app platforms, allowing customers to shop conveniently while
providing comprehensive data on purchasing patterns. Aurelia Styles is committed to
delivering high-quality products, personalized customer experiences, and strategic
promotions that drive engagement and loyalty.

## Rationale for the Project

<img src="https://github.com/user-attachments/assets/4f44aa7c-afbd-4b4f-ad7f-0a4ce4871e2d" width="100%" alt="Screenshot 2026-01-24 140339"  />

# Key Contributions
## 1. Development and Calculation of Key Performance Indicators (KPIs) üìä
I designed and executed SQL queries to calculate core retail KPIs, including total sales, net sales, transaction volumes, and units sold. By aggregating transactional data across products, customers, stores, and sales channels, I enabled a consistent and accurate measurement of business performance. These KPIs form the foundation for monitoring revenue trends and evaluating overall commercial health.

## 2. Transformation of Raw Transactional Data into Actionable Insights üîç
I applied SQL techniques such as joins, aggregations, and conditional logic to convert underutilised raw data into meaningful analytical outputs. This included analysing discounted versus non-discounted sales, identifying top-performing stores and regions, and assessing product category performance. These analyses provided clear, data-driven insights to support operational and strategic decision-making.

## 3. Customer Segmentation and Behavioural Analysis üë•
I conducted customer-level analysis to evaluate spending behaviour, purchase frequency, and the relative contribution of VIP and Regular customers. By linking sales and customer data, I identified high-value and repeat customers, supporting a deeper understanding of loyalty and customer value. This contribution enables more targeted marketing strategies and improved customer retention initiatives.

## 4. Product, Store, and Channel Performance Evaluation üõçÔ∏èüìç
I analysed performance trends across product categories, stores, regions, and sales channels to identify areas of strength and underperformance. This included assessing which categories perform best, which locations drive the highest sales, and which channels generate the most revenue. These insights support more effective inventory management, channel optimisation, and resource allocation.

## 5. Translation of SQL Analysis into Business-Focused Recommendations üöÄ
Beyond technical query development, I translated SQL outputs into clear, business-relevant insights aligned with Aurelia Styles‚Äô strategic objectives. This ensured that analytical findings could be readily used to inform decisions on inventory planning, promotional effectiveness, customer engagement, and overall business growth. My contribution supports the adoption of a data-driven decision-making approach across the organisation.

# Database Queries and Out-Put
## Codes I

<img  src="https://github.com/user-attachments/assets/6eeeb378-02d7-4d98-9df9-3f0cfc1cea72" width="100%" alt="Screenshot 2026-01-24 141654" />

- The first analysis focuses on identifying which product categories generate the highest net sales üìà. By integrating product-level data with transactional sales records, this query aggregates total sales at the product category level. The results are then ranked in descending order of revenue contribution, providing a clear view of which categories are driving the greatest proportion of overall sales performance. 
- The second analysis compares total net sales between VIP and Regular customer segments üë•. By linking customer segmentation data with sales transactions, the query calculates total revenue generated by each customer group. This provides a direct comparison of the financial impact of our customer segments.

## First Out-Put 

<img src="https://github.com/user-attachments/assets/83a5b79e-9bce-4c4a-ae4b-aa8e8fb25440" width="100%" alt="Screenshot 2026-01-24 143056" />

The resulting output presents each product category alongside its total net sales value üí∑, ordered from highest to lowest. This enables us to quickly pinpoint the categories that deliver the strongest financial returns and those that contribute less significantly. From a stakeholder perspective, this view offers a concise and actionable summary of revenue distribution across the product portfolio.
- The insight derived from this analysis is particularly valuable for strategic planning üéØ. It highlights the core revenue-generating categories that warrant continued investment, enhanced marketing focus, or range expansion. Conversely, lower-performing categories can be reviewed to assess pricing, positioning, or rationalisation opportunities, ensuring resources are allocated efficiently and in line with commercial priorities.

## Second Out-Put

<img src="https://github.com/user-attachments/assets/785c9d11-f11b-4b0b-995c-c6c3f421d6c7"  width="100%" alt="Screenshot 2026-01-24 144033" />

The output summarises total net sales by customer segment üìä, allowing us to clearly assess which group contributes more significantly to overall revenue. This comparison supports an evidence-based evaluation of customer value across the business.
- From an insight perspective, this analysis informs customer engagement and retention strategies üîç. A stronger revenue contribution from VIP customers would reinforce the importance of loyalty programmes and personalised incentives. Alternatively, a substantial contribution from Regular customers may indicate opportunities to drive growth through targeted upselling or segment conversion initiatives. Collectively, these insights support data-driven decision-making, improved customer strategy, and sustainable revenue growth üöÄ.

## Codes II

<img src="https://github.com/user-attachments/assets/e29de22e-51c1-491f-a003-f88583d4123f" width="100%" alt="Screenshot 2026-01-24 144346" />

- The first query is designed to identify which individual stores and regions are driving the highest levels of net sales üìç. This is achieved by joining the stores table with the sales table using the store identifier, ensuring that each sales transaction is accurately attributed to the correct store and region. The query then aggregates sales values using the SUM function and groups the results by both store name and region. By ordering the results in descending order of total net sales and limiting the output to the top five records, the analysis highlights the highest-performing store‚Äìregion combinations.
- The second query focuses on determining which sales channel generates the highest revenue across the business üîç. By joining the channels table with the sales table, each transaction is linked to its respective sales channel. The query aggregates total net sales by channel type, allowing for a direct comparison of revenue contribution across channels.

## First Out-Put

<img src="https://github.com/user-attachments/assets/9d7e9cc7-b050-400e-bd14-c24a96fd97f3" width="100%" alt="Screenshot 2026-01-24 145050" />

The intended output of this query is a ranked list of the top five stores, including their associated regions and total net sales üí∑. This output provides a concise and targeted view of where the strongest sales performance is occurring geographically and operationally. For stakeholders, this offers immediate visibility into which locations are delivering the greatest commercial impact. 
- The insights generated from this analysis are critical for location-based decision-making üéØ. Identifying top-performing stores and regions supports strategic actions such as prioritising investment, optimising staffing levels, expanding successful regional models, and replicating best practices across underperforming locations. It also enables leadership to assess regional performance disparities and respond with data-driven interventions where required.

## Second Out-Put

<img src="https://github.com/user-attachments/assets/ee32d725-5431-4166-859b-a01ec98c1c40" width="100%" alt="image"  />

The expected output is a summary table displaying each sales channel alongside its total net sales üìä. While the query limits the result set to a single row, the intention is to identify the highest-performing sales channel in terms of revenue generation.
 - The insight derived from this analysis supports channel strategy and investment decisions üöÄ. Understanding which channel delivers the greatest revenue enables the business to focus resources on the most effective routes to market, whether through digital platforms, physical stores, or third-party partnerships. It also informs future decisions around channel expansion, optimisation, and customer engagement strategies, ensuring sustained revenue growth and operational efficiency

## Codes III

<img src="https://github.com/user-attachments/assets/dcbde3ee-0455-4ac9-8ae5-34df88c86c6b" width="100%" alt="Screenshot 2026-01-24 150546" />

- The first query compares net sales generated from discounted versus non-discounted transactions üí∑. It uses a CASE statement to categorise each sale based on whether a discount was applied, classifying transactions as either Discounted or Not Discounted. The query then aggregates the net sales amount for each category by summing the relevant values and grouping the results by discount status. This approach provides a clear comparison of revenue performance between promotional and full-price sales.
- The second query identifies which customers appear most frequently and how much they spend over time üë•. By joining the sales and customers tables, each transaction is linked to the relevant customer. The query then calculates total spend per customer using the SUM function and measures purchase frequency by counting the number of transactions. Results are grouped by customer and ordered by total spend in descending order.
- The third query assesses which product categories perform best across stores by aggregating net sales at the product category level üõçÔ∏è. By joining sales data with both store and product information, the query ensures that sales are accurately attributed to the relevant product categories. The aggregation of net sales provides a clear measure of category-level performance.

## First Out-Put

<img src="https://github.com/user-attachments/assets/38b97f27-34bf-4a5e-953e-816f23c85aea" width="100%" alt="Screenshot 2026-01-24 151123" />

The intended output of this query is a summary table showing two rows, one for discounted transactions and one for non-discounted transactions, each with its corresponding total net sales üìä. This enables a direct assessment of how much revenue is generated through discounting activity versus standard pricing.
- The insight derived from this analysis supports pricing and promotional strategy decisions üéØ. If discounted transactions contribute a significant proportion of net sales, this may indicate that promotions are an effective driver of volume. However, if non-discounted sales dominate, it suggests strong price resilience and potential opportunities to reduce reliance on discounts while protecting margins.

## Second Out-Put

<img src="https://github.com/user-attachments/assets/a9dd7365-e7de-45bb-8805-1c2304470063" width="100%" alt="Screenshot 2026-01-24 151400" />

The expected output is a ranked list of customers showing customer identifiers, customer names, total amount spent, and total number of transactions üìà. This output highlights the customers who contribute most significantly to revenue and who engage most frequently with the business.
- The insights generated are highly valuable for customer relationship management and retention strategy üîç. This analysis identifies high-value and loyal customers who may benefit from targeted engagement, personalised offers, or loyalty incentives. It also supports risk management by highlighting revenue concentration among key customers.

## Third Out-Put

<img src="https://github.com/user-attachments/assets/198c1a1c-12d6-4a67-a899-4aa915f444c9" width="100%" alt="Screenshot 2026-01-24 151557" />

The intended output of this query is a table showing each product category alongside its total net sales üí∑. This allows for straightforward comparison of category performance across the retail estate.
- The insight generated from this analysis informs merchandising and assortment strategy üöÄ. Understanding which categories perform best supports decisions around stock allocation, space planning, and category-specific promotions. It also enables the business to align product strategy with customer demand patterns, supporting sustainable revenue growth and improved operational efficiency.


## POWER BI PROJECTS

### [Project 1: DESKIFY OFFICE SUPPLIES REPORT](https://github.com/akhimiejr/DESKIFY-OFFICE-SUPPLIES-REPORT)

Deskify Office Supply Co. is a leading retailer
specializing in office supplies,
technology/computer accessories, and furniture.
With a diverse product range catering to both
individual consumers and businesses, They have
experienced significant growth over the past four
years. Deskify Office Supply Co. is dedicated to
providing high-quality office essentials,
technology accessories, and furniture with a focus
on reliability, efficiency, and customer
satisfaction. 
# Key Contributions
## 1. End-to-End Data Interpretation and Insight Generation:
I conducted a full review of the dataset and dashboards, extracting key trends, patterns, and performance gaps across products, customers, regions, and operational processes. This included interpreting metrics such as revenue performance, profit margin, and order volume to form actionable analysis aligned with business priorities.
## 2. Critical Performance Evaluation Across Business Dimensions:
A structured assessment was completed across major analytical categories including product profitability, customer segmentation, geographic distribution, shipping behavior, and seasonal trends. This allowed for a comprehensive understanding of strengths, weaknesses, and operational inefficiencies affecting overall performance.
## 3. Strategic Improvement Recommendations:
I translated analytical findings into targeted business recommendations addressing profitability optimization, logistics cost control, product mix refinement, customer retention, and market expansion. These recommendations were aligned with practical business applications and designed to support margin improvement and growth strategy.
## 4. Data Storytelling and Insight Summarization:
The analysis was refined into clear, concise narrative summaries suitable for stakeholder communication. Insights were structured to support executive-level decision-making, ensuring the data could be easily understood, prioritized, and used to inform next steps across operational and strategic functions.
## 5. Model and Structure Review for Analytics Maturity:
Beyond visual insights, I evaluated the underlying Power BI data model, confirming appropriate schema structure, relationships, and calculated measure organization. This contribution supports scalability, maintainability, and future enhancements to reporting capabilities and analytical rigor.
# Data Modelling 
The data model represents a well-structured star schema centered on a single fact table, TransactionFact, which stores operational data such as revenue, profit, quantity, order dates, product IDs, and customer IDs. This fact table connects to multiple supporting dimension tables, including CustomerDim, ProductDim, OrderDim, LocationDim, and CalendarDim, each providing descriptive attributes for filtering, categorization, and analysis. All relationships are appropriately configured as one-to-many from dimensions to the fact table with single-direction filtering, which aligns with best practices for analytical reporting and avoids ambiguity. A separate "Calculated Measures" table is included, demonstrating strong governance by centralizing DAX calculations for maintainability. Overall, the model is clean, scalable, and optimized for Power BI reporting, though future refinements such as hierarchies, surrogate keys, and extended cost structures could further enhance analytical depth and long-term scalability.


<img src="https://github.com/user-attachments/assets/25f41cea-6431-4b3d-86ee-375af66ea137" width="100%" alt="Sales Performance Dashboard Screenshot" />


# Dashboard Reporting
## Product Performance Analysis
Deskify‚Äôs product performance shows strong revenue contribution from certain categories, with Furniture generating the majority of total profit at 985.36K (64.73%), followed by Office Supplies at 331.03K and Technology at 205.95K. Subcategory insight reveals key performers such as binders, paper, and furnishings, while the copier category operates at a loss of -16K, suggesting pricing issues, warranty expense, or high logistics overhead. Top individual products‚Äîincluding Eldon ClusterMat and Panasonic models‚Äîhighlight a dependency on a small set of profitable SKUs, creating product concentration risk. Operational data further indicates significant shipping cost pressure due to reliance on air freight (nearly 90% of orders), which likely diminishes margins and limits scale efficiency. Seasonal fluctuations in profitability also suggest the need for improved forecasting, inventory planning, and promotional timing. Overall, strengthening the product portfolio through cost optimization, renegotiated vendor terms, improved shipping strategy, and a focus on high-margin categories represents a key opportunity to unlock higher profitability.

<img src="https://github.com/user-attachments/assets/a76f588c-6e5d-41a4-92a2-ffcd3fa046fc" width="100%" alt="Screenshot 2025-11-28 165734" />

## Customer performance Analysis
Customer performance analysis reveals that profitability is concentrated among a small subset of high-value buyers, such as Emily Phan (34.01K), Deborah Brumfield (31.12K), and Grant Carroll (27.98K), introducing churn vulnerability if these customers reduce or discontinue purchases. Segment-level insights show the Corporate segment contributes the highest share of profit at 527.1K, while Home Office, Consumer, and Small Business segments collectively represent a significant portion, confirming that Deskify operates in both B2B and B2C markets. Geographic performance is similarly uneven, with the Northwest region generating the highest profit at 569,398, while regions such as Yukon and Quebec remain significantly underdeveloped. These patterns signal growth opportunities through targeted marketing, regional penetration strategies, and customer loyalty initiatives. Enhancing segmentation tactics, reducing reliance on top contributors, and activating underperforming markets could diversify revenue streams and strengthen customer-driven profitability over time.


<img src="https://github.com/user-attachments/assets/77d72a84-ac2a-404d-9a7d-23a12878133e" width="100%" alt="Screenshot 2025-11-28 165820"  />

### [Project 2: DREAMY BITES SALES ANALYSIS](https://github.com/akhimiejr/Dreamy-Bites)
Dreamy Bites is a premium cookie brand specializing in a variety of delectable treats, including chocolate chip, oatmeal raisin,and other gourmet cookies. The company has earned a reputation for delivering top-notch products to retailers and customers worldwide. As the business grows, analyzing sales trends, customer behavior, and product performance has become critical for strategic decision-making.
# Key Contributions
## 1. Multi-Source Data Integration and Modelling

Successfully consolidated fragmented business data from PDF, CSV, and Google Sheets into a single, structured Power BI data model. Designed a star schema with a central Orders fact table and supporting Customer and Product dimension tables, ensuring clean relationships, referential integrity, and scalable analytics.

## 2. Creation of Business-Ready Metrics Using DAX

Developed robust DAX measures to calculate key performance indicators such as Total Profit, Total Expenses, Quantity Sold, Number of Orders, and Profit Targets. Isolated calculations within a dedicated Measures table to improve model readability, performance, and reusability across multiple reports.

## 3. End-to-End Sales and Profitability Analysis

Delivered in-depth analysis of sales performance across products, customers, and time, enabling the business to identify high-margin products, top-performing customers, and loss-making areas. Visual comparisons of expenses versus profit provided clear insight into cost efficiency and pricing strategy.

## 4. Customer and Regional Insight Generation

Analysed customer purchasing behaviour and demographics by integrating customer location data with order performance. Built geographic and customer-level visuals to highlight regional profit concentration, order frequency, and volume contribution, supporting data-driven customer segmentation and targeted growth strategies.

## 5. Interactive Dashboard Design with Slicers

Designed intuitive, executive-level Power BI dashboards using slicers for Product and Customer, allowing stakeholders to dynamically filter and explore data. Ensured consistent visual hierarchy and storytelling across Customer and Product analysis views to enhance usability and decision-making.

## 6. Actionable Reporting for Strategic Decision-Making

Translated raw transactional data into actionable business insights that support inventory planning, product optimisation, and customer prioritisation. Enabled stakeholders to monitor trends over a 16-month period, identify seasonality, and align operational decisions with profitability and growth objectives.

# Data Modelling 
The data model shows a classic star schema, with the Order_Fact table at the centre capturing transactional data such as Order ID, Date, Expenses and Product. This fact table is linked via one-to-many relationships to the Customers_Dim table (containing customer attributes such as name, location and contact details) and the Product_Dim table (holding product types and unit-level production and selling costs). A dedicated Measures table is used to store calculated metrics, improving model clarity, reusability, and performance. This structure enables consistent filtering across visuals and underpins the slicers used in both dashboards.

<img src="https://github.com/user-attachments/assets/56c768c0-5a4b-4be0-b7bd-e98c65b2f3ee" width="100%" alt="Screenshot 2026-01-08 143222" />

# Dashboards Reporting
## Product Performance Analysis
The Product Analysis dashboard shifts focus to product performance while maintaining consistency in design and metrics. KPI cards summarise Total Profit (¬£3M), Total Orders (700), Total Expenses (¬£1.97M) and Number of Products (6), alongside order contribution metrics. A combined area and line chart tracks monthly total profit and quantity sold, revealing seasonal patterns and peak performance periods. Product-level bar charts compare expenses versus profit by product, highlighting cost efficiency and margin differences between cookie types. Additional visuals show quantity sold by product and rank products by total volume, making it easy to identify best-selling and underperforming items. A Name slicer allows users to filter the dashboard by customer, ensuring seamless cross-analysis between customer and product perspectives.

<img src="https://github.com/user-attachments/assets/f77a5c4b-0a56-4096-a0c9-cd101e039837" width="100%" alt="Screenshot 2026-01-08 143517"/>

## Customer Performance Analysis
The Customer Analysis dashboard focuses on customer-level performance. KPI cards at the top summarise headline metrics, including Total Profit (¬£3M), Total Orders (700), Total Customers (5) and Total Expenses (¬£1.97M). Gauge visuals provide immediate context by comparing Customer Profit against a target and showing Total Quantity Sold (1,125,824 units) against an upper benchmark. A geographical map visual displays customer profit by state, highlighting regional concentration and performance differences across the United States. Below, bar charts break down total expenses versus profit by customer, clearly illustrating margin performance for each customer, while additional visuals show quantity sold by customer name and number of orders per customer, allowing easy identification of high-volume and high-frequency buyers. A Product slicer enables users to dynamically filter all visuals to analyse customer behaviour for specific products.

<img src="https://github.com/user-attachments/assets/faf26447-5613-4d86-b68b-4a7e0090f4d6" width="100%" alt="Screenshot 2026-01-08 143448" />


### [Project 3: TRI-FLEET INDUSTRIES ANALYTICS](https://github.com/akhimiejr/Tri-Fleet-Industries-)

Tri-Fleet Industries is a specialised global retailer focused on vintage and classic vehicles, including cars, trucks, buses, trains, motorcycles, ships, and other collectible transport assets. The company serves a broad, high-value clientele across international markets, offering a distinctive portfolio of rare and sought-after vehicles. Through its diverse product range and worldwide reach, Tri-Fleet Industries operates within a niche market that combines heritage value with premium retail demand, positioning the business as a key provider of specialist and collectible vehicles globally.
# Key Contributions

## 1. Development of an End-to-End Analytics Dashboard
Designed and delivered a comprehensive Power BI dashboard that consolidates sales performance across products, customers, geographies, and time, enabling stakeholders to gain a clear, single-source view of business performance.

## 2. Product and Customer Performance Analysis
Analysed product categories and customer sales patterns to identify key revenue drivers, concentration risks, and underperforming segments, providing insights to support product portfolio optimisation and customer diversification strategies.

## 3. Identification of Geographic and Seasonal Trends
Evaluated sales distribution by country and analysed time-based trends to uncover regional performance gaps and seasonal fluctuations, supporting more accurate forecasting, market expansion planning, and inventory alignment.

## 4. Implementation of Data Security and Governance
Configured Row-Level Security (RLS) roles to restrict data visibility by territory, ensuring secure, role-appropriate access to sensitive sales data and aligning the solution with data governance best practices.

## 5. Report Deployment and Stakeholder Enablement
Published the report to the Power BI Service, created a dedicated workspace and app for controlled sharing, and structured the dashboard for usability, ensuring stakeholders could easily access, interact with, and act on the insights provided.
# Dashboards Reporting
The Tri-Fleet Industries Analytics dashboard provides a comprehensive, data-driven overview of sales performance across products, customers, locations, and time, enabling stakeholders to assess overall business health, identify key revenue drivers, and uncover risks and opportunities through high-level KPIs and interactive analysis. With total sales of $10.03M from 99,067 units sold, the business demonstrates strong demand and commercial performance, although further margin analysis is required to fully assess profitability efficiency. Sales are heavily driven by Classic Cars, which significantly outperform other product lines, indicating both a core strength and a concentration risk, while weaker categories such as Trains may require repositioning or strategic review. Revenue concentration is also evident among top customers, particularly Euro Shopping Channel and Mini Gifts Distributors, highlighting the importance of customer diversification to reduce reliance on a small number of key accounts. Geographically, sales are concentrated in North America and Europe, with limited presence in emerging markets, presenting opportunities for expansion subject to logistical and regulatory considerations. Sales trends reveal clear seasonality, with pronounced peaks and troughs suggesting opportunities for improved forecasting, inventory planning, and targeted marketing. Overall, while Tri-Fleet Industries demonstrates strong sales performance, addressing product, customer, and regional concentration alongside seasonal volatility will be critical to achieving sustainable long-term growth.

<img  src="https://github.com/user-attachments/assets/59d6aa95-9c0a-4976-993f-54f6d045ed7c" width="100%" alt="Screenshot 2025-12-16 110611" />

# Row-Level Security

# APAC MANAGER

<img src="https://github.com/user-attachments/assets/50258e30-03ad-4420-a9ba-4c010fae2954"  width="100%" alt="Screenshot 2025-12-16 120336" />

# EMEA MANAGER

<img src="https://github.com/user-attachments/assets/52898bca-03b8-4de0-bb84-2e66fe852666" width="100%" alt="Screenshot 2025-12-16 120402" />

# JAPAN MANAGER

<img src="https://github.com/user-attachments/assets/c5b50ba0-0a9d-4e68-9291-3b664f63f60d"  width="100%" alt="Screenshot 2025-12-16 120641"  />


# NORTH AMERICA MANAGER

<img src="https://github.com/user-attachments/assets/37323faf-b013-46d8-b1f1-95c8fa452933" width="100%" alt="Screenshot 2025-12-16 120706" />


### [Project 4: GLOBAL INSIGHT ANALYTICS](https://github.com/akhimiejr/GLOBAL-INSIGHT-ANALYTICS)
This report presents a comprehensive global demographic analysis, illustrating how the world population has evolved over time, how it is geographically distributed today, and how it is segmented by major religious affiliations. The structure of the report allows the reader to develop an understanding of long-term trends, present-day population concentration, and underlying cultural composition. Power BI has been used to extract data directly from online sources, enabling automation, periodic refresh, and continuous accuracy as global data updates. The design and analytical flow position the report as both a reference tool and a dashboard for ongoing monitoring.
# Key Contributions
## 1. Sourced and Extracted Live Global Demographic Data
Identified reliable online data repositories, including global population and demographic databases, and successfully connected Power BI to these sources using the Web Connector to automate data import and retrieval.

## 2. Cleaned, Transformed, and Standardised Raw Data for Accuracy
Used Power Query to remove duplicates, correct formatting inconsistencies, apply uniform data types, and merge fragmented datasets, ensuring all values were reliable, analysable, and aligned across time periods and categories.

## 3. Developed a Robust Analytical Data Model and Calculation Framework
Designed relationships between country-level, regional, and category-based demographic tables and built DAX measures to calculate totals, percentages, projections, and comparative metrics essential for meaningful insight.

## 4. Designed Clear, Insight-Driven Visualisations and Layout Structure
Applied best practices in data visualisation to build maps, trend charts, and comparative analysis visuals that clearly communicated historical growth patterns, regional distribution, and cultural population characteristics.

## 5. Implemented Scheduled Refresh and Insight Interpretation for Decision Support
Enabled automated updates through Power BI Service so the dashboard reflects the latest available data over time, and provided narrative insight and interpretation, transforming raw data into a meaningful analytical tool for ongoing use.
# Web Page
https://www.worldometers.info/world-population/

<img src="https://github.com/user-attachments/assets/c6a86232-3e3b-4ca8-a2ec-0479f1bd62d7" width="100%" alt="Screenshot 2025-12-07 180038" />

# Dashboard Reporting
The report demonstrates effective use of Power BI‚Äôs online data connectivity features. Online data sources could have been accessed through the Web connector in Power Query, enabling extraction from APIs, publicly available data portals, or structured web tables such as the World Bank datasets, United Nations population tables, or Pew Research data. Transformations would have included filtering, normalising values, and establishing data types suitable for calculations and modelling. Data relationships would then be maintained in a structured model, potentially using a star schema for clarity and efficiency. Measures and aggregations were likely written using DAX to compute totals, percentages, and growth indicators. Once published to Power BI Service, scheduled refresh functionality ensures that the report updates automatically in alignment with new data releases. The report is visually clear and logically structured. It progresses from historical context through present-day geographic distribution and finally into cultural demographic segmentation. The colour consistency, geographic mapping, clean labelling, and strong visual hierarchy contribute to professionalism and readability. The report format is scalable and capable of supporting additional views such as forecast projections, age structure analysis, or socio-economic overlays.

<img src="https://github.com/user-attachments/assets/275ad198-30c6-475f-9689-35dc7166a9ee"  width="100%" alt="Screenshot 2025-12-07 173211"  />

### [Project 5:PURE SIP'S BEVERSGES](https://github.com/akhimiejr/PureSip-Beverages)
PureSip Beverages is a growing beverage distribution company supplying popular brands such as Coke, Fanta, Sprite, and other leading soft drinks to major retailers including Costco, Walgreens, Target, and Walmart. As the organisation expanded, sales reporting became increasingly fragmented due to reliance on separate spreadsheets managed by regional managers. To address challenges related to data consolidation, reporting accuracy, and analytical capability, PureSip implemented a Power BI solution using a centralised folder connection and automated refresh, enabling real-time visibility of performance across all locations.

# Key Contributions

## 1. Centralised Data Management
PureSip Beverages implemented a robust shared folder structure accessible to all relevant stakeholders within the organisation. This centralised repository serves as the single source of truth for all regional sales data, replacing fragmented spreadsheets managed individually by regional managers. By consolidating all sales files into a unified, organised structure, the company eliminated duplication of effort, simplified data governance, and ensured that all teams work from consistent, up-to-date information.

## 2. Automated Data Refresh and Integration
Leveraging Power BI‚Äôs folder connection capability, the company automated the detection and integration of new sales spreadsheets as soon as they are uploaded to the shared folder. This automation removes the need for manual data consolidation, significantly reducing the time and effort required to prepare reports. The continuous, real-time data refresh ensures that decision-makers always have access to the most current information, enabling timely responses to market trends and sales opportunities.

## 3. Enhanced Data Accuracy and Consistency
By standardising the data collection process and automating integration, PureSip reduced errors arising from inconsistent spreadsheet formats, manual entry mistakes, and data duplication. This approach ensures high-quality, reliable data across all retailers and regions. Consistent data improves confidence in reports, reduces the risk of misinformed decisions, and allows management to track performance trends with greater accuracy.

## 4. Improved Reporting and Analytics Capability
The transition from static spreadsheets to Power BI enabled advanced reporting and analytical capabilities that were previously unattainable. The company can now leverage interactive dashboards, trend analysis, geographic visualisation, and performance comparisons across regions. These capabilities provide actionable insights into sales performance, help identify growth opportunities, and support strategic decision-making with clear, data-driven evidence.

## 5.Operational Efficiency and Scalability
Automating the data integration and reporting process freed staff from repetitive manual tasks such as consolidating spreadsheets and reconciling errors. This operational efficiency allows teams to focus on higher-value activities, such as analysing trends or developing sales strategies. Furthermore, the system is designed to scale easily: as PureSip expands to additional regions or retailers, the same folder structure and Power BI connection can accommodate new data without requiring structural changes, ensuring long-term sustainability of the reporting framework.

# Dashboard Reporting
This Report provides a comprehensive, filter-driven sales analysis for Pure Sip, incorporating slicers for Beverage Brand and Contact to allow users to tailor the view to specific product lines or customer groups. The KPI panel shows current performance against targets, with sales of ¬£238,850, which is ¬£11,150 below the ¬£250,000 goal (‚Äì4.46%). Total sales amount to ¬£1,213,018, supported by 2,309,850 units sold across four retailers. The sales trend visual illustrates month-by-month performance, rising from ¬£82.1K in January to a peak of ¬£116K in August, before stabilising around ¬£115K in December. Below, regional analysis maps sales across key North American states, while brand performance charts identify Dasani Water, Coca-Cola, and Diet Coke as the leading contributors. Retailer analysis highlights Walmart as the top performer with ¬£391.8K, followed by Costco, Walgreens, and Target. Together with the interactive slicers, the dashboard enables dynamic exploration of trends, channel contributions, and performance variations, supporting informed decision-making and targeted strategy refinement.


<img src="https://github.com/user-attachments/assets/950294e9-9803-4a0d-b3b7-6ab9aa1f5181" width="100%" alt="Screenshot 2025-12-07 191117" />


## EXCEL PROJECTS
### [Project 1: CAFE-HARMONY-PROJECT](https://github.com/akhimiejr/CAFE-HARMONY-PROJECT-)
At Caf√© Harmony, we have been navigating a period of impressive growth, which has brought new challenges as we scale to meet increasing customer demand with multiple locations across the city, each with unique customer preferences and performance metrics, maintaining efficient operations and delivering a consistently high-quality experience has become increasingly complex.
To address these challenges, My team and I proactively applied Root Cause Analysis (RCA) to uncover the underlying sources of inefficiency, implemented Lean Management principles to streamline operations and reduce waste, and leveraged Data-Driven Decision Making (DDDM) to track sales trends and performance metrics across all locations. We also embraced Continuous Improvement (Kaizen) practices to support sustainable growth and long-term operational excellence. Simultaneously, we conducted in-depth customer analysis to refine service delivery and elevate satisfaction, ensuring every customer interaction aligns with Caf√© Harmony‚Äôs high standards.
Through these initiatives, we are focused on optimizing resource management, enhancing staff performance, and strengthening service strategies creating a foundation for sustainable growth while continuing to provide the exceptional experience that our customers have come to expect
# Key Contributions
## Data Cleaning and Preparation

I ensured all operational and sales datasets were meticulously cleaned and standardised, making them ready for detailed analysis. This step eliminated inconsistencies and errors, creating a reliable foundation for accurate insights across multiple caf√© locations.

## Comprehensive Data Analysis

Using advanced Excel formulas such as SUMIF, COUNTIF, VLOOKUP, and INDEX/MATCH, we analysed sales, product performance, employee performance, and customer trends. This enabled precise measurement of key metrics and identification of performance gaps across locations.

## Dashboard Creation and Visualisation

I developed interactive dashboards using pivot tables, slicers, and charts to visually communicate business insights. These dashboards provided real-time visibility into sales trends, product performance, customer demographics, and inventory status, enabling quicker, informed decisions.

## Sales Performance Insights

By tracking overall sales trends across all locations, I identified periods of peak performance and potential slowdowns. This allowed management to optimise promotions, staffing, and operational focus to maximise revenue consistently.

## Product and Stock Performance Optimisation

Analysis of menu items highlighted top-selling products generating the highest revenue, as well as low running stock items across locations. This insight supported targeted inventory management and menu adjustments, reducing waste and improving profitability.

## Employee Performance Assessment

I evaluated staff performance by correlating individual sales data with location benchmarks. Identifying above and below average performers enabled focused training, performance recognition, and operational improvements to enhance overall team efficiency.

## Customer Insights and Feedback Analysis

Customer demographics and satisfaction data were analysed to uncover trends driving the highest sales and overall satisfaction. These insights informed service enhancements, personalised offers, and engagement strategies, ensuring a consistently exceptional customer experience.
# Pivot Table Analysis

<img src="https://github.com/user-attachments/assets/f04d8815-54a5-4340-bf9c-7026881abbc3" width="100%" alt="Screenshot 2025-11-30 100745" />


The image Above displays an Excel workbook transformed into a compact analytics dashboard using PivotTables, summary statistics, and visual charts to provide a comprehensive, data-driven overview of key business performance metrics for caf√© Harmony

# Dashboard


<img src="https://github.com/user-attachments/assets/8b52bb36-94ab-4c3c-a26c-14ae7d285903"  width="100%" alt="Screenshot 2025-11-23 130931" />


The Cafe Harmony Sales & Performance Dashboard provides a comprehensive insight of the caf√©‚Äôs overall business health, showing total sales of ¬£12,589.95 generated from 1003 customers, with 10 main stock items tracked and an average customer rating of 3.05. Monthly sales trends reveal fluctuations throughout the year, peaking in May and dipping in March, while demographic data shows a nearly even distribution across young adults, adults, and elderly customers. Product performance highlights Muffins, Latte, and Iced Tea as top revenue generators, whereas items like Cappuccino and Sandwiches perform less strongly. Stock movement indicates high usage of milk, croissant dough, and iced tea bags, contrasted with increases in sugar and coffee beans. Staff performance displays notable variation, with high achievers like Megan White outperforming others. Rating analysis reveals a predominance of 4- and 5-star reviews despite the moderate overall average. Together, these insights show strong product engagement, steady customer traffic, opportunities for inventory optimization, and areas for staff development and service improvement.


## PYTHON PROJECTS
### [Project 1: CRIME ANALYSIS REPORT](https://akhimiejr.github.io/CRIME-ANALYSIS-REPORT-FROM/)

The project analyzes various crime types, such as violent and non-violent crimes, to understand their frequency, affected demographics, times of occurrence, and geographical distribution. Using Python, Jupyter Notebook, and libraries like pandas, matplotlib, seaborn, scikit-learn, and plotly, the analysis employs machine learning models Logistic Regression, Decision Trees, and Random Forest to predict crime likelihood and identify key contributing factors. The practical applications are significant, enabling financial institutions to prevent crime and allowing the LAPD to optimize patrols based on crime patterns. The study also integrates current crime detection and prevention methodologies, such as statistical analysis, GIS for spatial insights, and real-time alert systems, aiming to enhance public safety and resource efficiency.
##  Key Contributions
###  Model Development 
I designed and implemented machine learning models including Logistic Regression, Decision Trees, and Random Forest to predict the likelihood of crimes based on time, location, and demographic information. I also developed a predictive service to support law enforcement agencies in proactive crime prevention and optimized resource deployment.
###  Crime Variable Description  
I analyzed a dataset of over 944,000 LAPD crime reports and documented 28 key variables, including crime types, victim demographics, weapon use, geographic data, and timestamps. This analysis was critical to understanding crime patterns and contextual factors.
###  Data Visualisation  
Using libraries like matplotlib, seaborn and plotly, I created interactive and static visualizations to show crime trends over time, geographic concentrations, and demographic patterns. These visual tools helped uncover important insights and supported model development.
###  Statistical Modeling  
I conducted **correlation analysis** to explore relationships between variables such as time, location, and victim demographics. These statistical insights informed **feature selection** and improved the interpretability and performance of the machine learning models.
###  Data Cleaning  
I cleaned and preprocessed the raw crime data by handling missing values (e.g., coordinates like (0¬∞, 0¬∞)), fixing formatting issues, and removing inconsistencies. This ensured a clean, reliable dataset for accurate analysis and modeling.
#  Some Visualisation
![Screenshot 2024-05-23 113006](https://github.com/user-attachments/assets/7649b681-9448-4a18-b83d-cde628c75764)

Pie chart of weapons used in crime by district in Los Angeles

![Screenshot 2024-05-23 111746](https://github.com/user-attachments/assets/7af26b35-c15f-49d0-8bb6-4e8ebb171754)

This bar chart visualizes crime rates across different regions or districts in Los Angeles

![Screenshot 2024-05-23 134108](https://github.com/user-attachments/assets/df7b0c1d-dbff-40a9-99b7-964def1a1350)

Time series analysis

![Screenshot 2024-05-23 161411](https://github.com/user-attachments/assets/adfe7d1d-4530-48b0-bca8-7ef4c7ecf426)

Decision Trees

### [Project 2: Credit Card Fraud Detection](https://akhimiejr.github.io/Credit-Card-Fraud-Detection-/)

Fraud is a pervasive issue that affects businesses across various industries, leading to 
significant financial losses and reputational damage. With the advent of digital transactions 
and e-commerce, the risk of fraud has escalated, necessitating robust fraud detection and 
prevention mechanisms. This study aims to leverage data analytics and historical transaction 
data to uncover insights and develop robust fraud prevention strategies and anomalies that 
can indicate fraudulent activities, thereby enabling organizations to take proactive measures 
to mitigate fraud risks.

 ## Aim and Objectives 
The primary aim of this Project is to analyse a credit card fraud dataset to the identify patterns 
and gain a comprehensive insight that can aid in the detection and prevention of fraudulent 
activities. This will assist the banking industry in making critical step by which their 
customers use their credit card for transactions.  
The transaction data set that is being explored will also assist the companies in exploring their 
customer spending habits, age groups that transact the most, time period where transactions 
occur, helping the company plan resource allocation there by optimising response time from 
their customer care departments. 
## Key Contributions 
- Perform exploratory data analysis on the fraud dataset to understand the nature and 
characteristics of the data. 
- Identify key factors and variables that contribute to the likelihood of fraudulent 
transactions. 
- Develop strategies and techniques for detecting and preventing fraud based on the insights 
gained from the analysis. 
- Compare the effectiveness and efficiency of SAS and Tableau in performing fraud 
analytics and data visualization.

## Some Visualisation
<img width="386" alt="Screenshot 2025-04-21 140935" src="https://github.com/user-attachments/assets/5c63184e-34c8-472b-afcb-84c11d8b8b2e" />

 Box plot of age of customer by gender 
 
In the above figure, it is demostrated that on average the male customers are older than the 
female customer. With the female customer on average being in their forties and the male 
customers are in their fifties. This insight os quite significant as stakeholders in the 
customer experience team can use this detial and reach out to older customers especially, 
giving them training on how to spot fraudulent transactions there by curbing the risk of them 
falling victim to scam.

![Screenshot 2025-04-21 143046](https://github.com/user-attachments/assets/adaa7198-4531-4d4f-bbe9-edd9acb9dda6)

Pie chart showing the spend range and total fraudulent amount.

Our earlier analysis showed that the average amount spent on any transaction by a customer, 
either female or male was $71,  which is a characteristic of fraudulent transactions, the observation is that fraudulent transactions tend to be three times 
or higher the average spend of a customer. This makes sense as scammers would want to cash 
in big in order to get away with as much more as they can.  

![Screenshot 2025-04-21 143507](https://github.com/user-attachments/assets/84ed3e56-f656-4d71-8fb8-7fc2491884dc)

Age distribution, gender, and fraudulent activity

![Screenshot 2025-04-21 143653](https://github.com/user-attachments/assets/12f7f63a-e253-4e14-a33d-4d7a15f29611)

 Bar chart of age bracket targeted by fraudsters 

Imploring a bar graph to assist in buttressing the insight of our analysis, we can see that middled 
aged male customer are the most defrauded within our customer base followed by elderly 
women and young women. Teenage male customers also tend to fall victim as well.

### [Project 3: Predictive Analysis of Neurological Disorder Susceptibility Pattern for Urban Elderly Population](https://github.com/akhimiejr/PREDICTIVE-ANALYSIS-DEMENTIA-)

This study investigates dementia susceptibility among urban elderly populations, a group particularly vulnerable due to socio-environmental factors like stress, pollution, and lifestyle. Recognizing limitations in existing research‚Äîsuch as data diversity, model generalizability, and clinical integration‚Äîthe study employs advanced machine learning techniques such as logistic regression and neural networks to improve early detection and prediction accuracy. The research combines a literature review with analysis of demographic and health data from urban healthcare centers to identify key dementia risk factors.
## Project Aim and Objectives
The primary aim of this research project is to develop a robust predictive Magnetic Resonance Imaging model that can accurately identify and classify dementia in urban populations using advanced machine learning techniques. The study seeks to address the gaps in current dementia research by focusing on the unique environmental, social, and economic factors prevalent in urban settings, which may influence the onset and progression of dementia. To achieve this aim, the following objectives have been established
-	Develop a brain MRI-based model to classify dementia stages in urban populations, aiming to surpass the accuracy of generalized models. This will enhance early detection and targeted treatment for urban individuals.
- Identify urban-specific risk factors like pollution and social isolation that influence dementia onset and progression. Incorporate these factors into predictive models for better relevance and accuracy.
-	Investigate disparities in dementia care related to socio-economic status, ethnicity, and cultural factors in urban settings. Identify key factors to address inequities and improve care quality.
-	Create recommendations to enhance urban dementia care through early diagnosis, personalized treatment, and equitable access. Guide policymakers and healthcare providers with evidence-based strategies.
## Key contribution
This Project contributes significantly to public health by developing predictive models tailored to urban elderly populations, revealing key socio-economic and environmental risk factors for dementia. These insights can inform targeted public health policies, such as reducing pollution and improving mental health services. Clinically, the study enhances early detection and personalized care through predictive analytics, improving diagnosis and treatment outcomes. It also lays the groundwork for future research into the mechanisms of urban-related dementia risk and encourages the application of similar methods to other neurological disorders. Overall, the study offers actionable insights to better understand and address dementia in urban settings.
# Some Visualisation
![image](https://github.com/user-attachments/assets/a6aa7430-ec58-4ab5-b213-483cc32e4917)

Exploratory data labelling

![image](https://github.com/user-attachments/assets/248ac053-1c21-4948-9283-34c71a11f6fa)

The bar chart provides a visual summary of the precision, recall, and F1-score for a classification model across four classes.

![image](https://github.com/user-attachments/assets/9a1b3253-3026-4134-aad2-463cae13f34c)

The confusion matrix highlights the model's performance across four classes: Non demented, Mild Dementia, Moderate Dementia, and Very mild Dementia





---



